{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Civitai Model Downloader for ComfyUI\n",
    "\n",
    "This notebook helps you download models from Civitai directly to your ComfyUI checkpoints folder.\n",
    "\n",
    "## Features:\n",
    "- Download models by URL or model ID\n",
    "- Automatic file naming with model info\n",
    "- Progress bar for downloads\n",
    "- Support for different model types (checkpoints, LoRA, VAE, etc.)\n",
    "- Resume interrupted downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not already installed\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Check and install required packages\n",
    "try:\n",
    "    import requests\n",
    "except ImportError:\n",
    "    print(\"Installing requests...\")\n",
    "    install_package(\"requests\")\n",
    "    import requests\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    print(\"Installing tqdm...\")\n",
    "    install_package(\"tqdm\")\n",
    "    from tqdm import tqdm\n",
    "\n",
    "print(\"âœ… All required packages are installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import time\n",
    "\n",
    "# Configuration - Update these paths for your setup\n",
    "COMFYUI_BASE_PATH = \"/workspace/ComfyUI\"  # Update this to your ComfyUI installation path\n",
    "\n",
    "# Model type to folder mapping\n",
    "MODEL_FOLDERS = {\n",
    "    \"checkpoint\": \"models/checkpoints\",\n",
    "    \"lora\": \"models/loras\",\n",
    "    \"vae\": \"models/vae\",\n",
    "    \"upscaler\": \"models/upscale_models\",\n",
    "    \"controlnet\": \"models/controlnet\",\n",
    "    \"ipadapter\": \"models/ipadapter\",\n",
    "    \"clip\": \"models/clip\",\n",
    "    \"embedding\": \"models/embeddings\"\n",
    "}\n",
    "\n",
    "# Civitai API configuration\n",
    "CIVITAI_API_KEY = \"\"  # Optional: Add your Civitai API key for faster downloads\n",
    "\n",
    "print(f\"ðŸ“ ComfyUI Base Path: {COMFYUI_BASE_PATH}\")\n",
    "print(\"\\nðŸ“‚ Model folders:\")\n",
    "for model_type, folder in MODEL_FOLDERS.items():\n",
    "    full_path = os.path.join(COMFYUI_BASE_PATH, folder)\n",
    "    exists = \"âœ…\" if os.path.exists(full_path) else \"âŒ\"\n",
    "    print(f\"  {exists} {model_type}: {folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CivitaiDownloader:\n",
    "    def __init__(self, base_path=COMFYUI_BASE_PATH, api_key=None):\n",
    "        self.base_path = base_path\n",
    "        self.api_key = api_key\n",
    "        self.session = requests.Session()\n",
    "        if api_key:\n",
    "            self.session.headers.update({\"Authorization\": f\"Bearer {api_key}\"})\n",
    "    \n",
    "    def extract_model_info(self, url):\n",
    "        \"\"\"Extract model ID and version ID from Civitai URL\"\"\"\n",
    "        # Pattern for model URLs: https://civitai.com/models/[model_id]\n",
    "        # Pattern for direct download: https://civitai.com/api/download/models/[version_id]\n",
    "        \n",
    "        if \"api/download/models\" in url:\n",
    "            match = re.search(r'/models/(\\d+)', url)\n",
    "            if match:\n",
    "                return None, match.group(1)\n",
    "        else:\n",
    "            match = re.search(r'/models/(\\d+)', url)\n",
    "            if match:\n",
    "                model_id = match.group(1)\n",
    "                # Check for version in URL\n",
    "                version_match = re.search(r'modelVersionId=(\\d+)', url)\n",
    "                version_id = version_match.group(1) if version_match else None\n",
    "                return model_id, version_id\n",
    "        \n",
    "        return None, None\n",
    "    \n",
    "    def get_model_details(self, model_id=None, version_id=None):\n",
    "        \"\"\"Fetch model details from Civitai API\"\"\"\n",
    "        try:\n",
    "            if version_id:\n",
    "                # Get version details\n",
    "                api_url = f\"https://civitai.com/api/v1/model-versions/{version_id}\"\n",
    "                response = self.session.get(api_url)\n",
    "                if response.status_code == 200:\n",
    "                    return response.json()\n",
    "            \n",
    "            if model_id:\n",
    "                # Get model details\n",
    "                api_url = f\"https://civitai.com/api/v1/models/{model_id}\"\n",
    "                response = self.session.get(api_url)\n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    # Return the latest version\n",
    "                    if data.get('modelVersions'):\n",
    "                        return data['modelVersions'][0]\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Failed to fetch model details: {e}\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def determine_model_type(self, model_info):\n",
    "        \"\"\"Determine the model type from model info\"\"\"\n",
    "        if not model_info:\n",
    "            return \"checkpoint\"\n",
    "        \n",
    "        # Check model type from API response\n",
    "        model_type = model_info.get('model', {}).get('type', '').lower()\n",
    "        \n",
    "        type_mapping = {\n",
    "            'checkpoint': 'checkpoint',\n",
    "            'lora': 'lora',\n",
    "            'locon': 'lora',\n",
    "            'vae': 'vae',\n",
    "            'upscaler': 'upscaler',\n",
    "            'controlnet': 'controlnet',\n",
    "            'textualinversion': 'embedding',\n",
    "            'embedding': 'embedding'\n",
    "        }\n",
    "        \n",
    "        return type_mapping.get(model_type, 'checkpoint')\n",
    "    \n",
    "    def get_download_url(self, model_info, version_id=None):\n",
    "        \"\"\"Get the direct download URL for a model\"\"\"\n",
    "        if not model_info:\n",
    "            if version_id:\n",
    "                return f\"https://civitai.com/api/download/models/{version_id}\"\n",
    "            return None\n",
    "        \n",
    "        # Get the primary file\n",
    "        files = model_info.get('files', [])\n",
    "        if files:\n",
    "            primary_file = files[0]  # Usually the main model file\n",
    "            download_url = primary_file.get('downloadUrl')\n",
    "            if download_url:\n",
    "                return download_url\n",
    "        \n",
    "        # Fallback to version ID\n",
    "        version_id = model_info.get('id')\n",
    "        if version_id:\n",
    "            return f\"https://civitai.com/api/download/models/{version_id}\"\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def get_filename(self, model_info, response_headers=None):\n",
    "        \"\"\"Generate a filename for the model\"\"\"\n",
    "        filename = None\n",
    "        \n",
    "        # Try to get filename from model info\n",
    "        if model_info:\n",
    "            files = model_info.get('files', [])\n",
    "            if files:\n",
    "                filename = files[0].get('name')\n",
    "            \n",
    "            if not filename:\n",
    "                # Generate filename from model name and version\n",
    "                model_name = model_info.get('model', {}).get('name', 'model')\n",
    "                version_name = model_info.get('name', 'v1')\n",
    "                model_name = re.sub(r'[^\\w\\s-]', '', model_name).strip()\n",
    "                version_name = re.sub(r'[^\\w\\s-]', '', version_name).strip()\n",
    "                filename = f\"{model_name}_{version_name}.safetensors\"\n",
    "        \n",
    "        # Try to get filename from response headers\n",
    "        if not filename and response_headers:\n",
    "            content_disposition = response_headers.get('content-disposition', '')\n",
    "            if 'filename=' in content_disposition:\n",
    "                filename = content_disposition.split('filename=')[1].strip('\"')\n",
    "        \n",
    "        # Default filename\n",
    "        if not filename:\n",
    "            filename = f\"model_{int(time.time())}.safetensors\"\n",
    "        \n",
    "        return filename\n",
    "    \n",
    "    def download_file(self, url, destination, filename=None, resume=True):\n",
    "        \"\"\"Download a file with progress bar and resume support\"\"\"\n",
    "        headers = {}\n",
    "        mode = 'wb'\n",
    "        resume_pos = 0\n",
    "        \n",
    "        # Check if file exists for resume\n",
    "        if resume and filename:\n",
    "            filepath = os.path.join(destination, filename)\n",
    "            if os.path.exists(filepath):\n",
    "                resume_pos = os.path.getsize(filepath)\n",
    "                headers['Range'] = f'bytes={resume_pos}-'\n",
    "                mode = 'ab'\n",
    "                print(f\"ðŸ“‚ Resuming download from {resume_pos:,} bytes\")\n",
    "        \n",
    "        # Start download\n",
    "        response = self.session.get(url, headers=headers, stream=True)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Get filename if not provided\n",
    "        if not filename:\n",
    "            filename = self.get_filename(None, response.headers)\n",
    "        \n",
    "        # Get total file size\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        if resume_pos > 0:\n",
    "            total_size += resume_pos\n",
    "        \n",
    "        # Create destination directory\n",
    "        os.makedirs(destination, exist_ok=True)\n",
    "        filepath = os.path.join(destination, filename)\n",
    "        \n",
    "        # Download with progress bar\n",
    "        with open(filepath, mode) as f:\n",
    "            with tqdm(total=total_size, initial=resume_pos, unit='B', unit_scale=True, desc=filename) as pbar:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "                        pbar.update(len(chunk))\n",
    "        \n",
    "        return filepath\n",
    "    \n",
    "    def download_model(self, url, model_type=None, custom_name=None):\n",
    "        \"\"\"Main download function\"\"\"\n",
    "        print(f\"\\nðŸ” Processing URL: {url}\")\n",
    "        \n",
    "        # Extract model information\n",
    "        model_id, version_id = self.extract_model_info(url)\n",
    "        \n",
    "        # Get model details from API\n",
    "        model_info = self.get_model_details(model_id, version_id)\n",
    "        \n",
    "        if model_info:\n",
    "            model_name = model_info.get('model', {}).get('name', 'Unknown')\n",
    "            version_name = model_info.get('name', 'Unknown')\n",
    "            print(f\"ðŸ“¦ Model: {model_name} - {version_name}\")\n",
    "        \n",
    "        # Determine model type\n",
    "        if not model_type:\n",
    "            model_type = self.determine_model_type(model_info)\n",
    "        print(f\"ðŸ“ Model Type: {model_type}\")\n",
    "        \n",
    "        # Get destination folder\n",
    "        folder = MODEL_FOLDERS.get(model_type, MODEL_FOLDERS['checkpoint'])\n",
    "        destination = os.path.join(self.base_path, folder)\n",
    "        \n",
    "        # Get download URL\n",
    "        download_url = self.get_download_url(model_info, version_id)\n",
    "        if not download_url:\n",
    "            download_url = url  # Use original URL as fallback\n",
    "        \n",
    "        # Add API key to URL if available\n",
    "        if self.api_key and 'civitai.com' in download_url:\n",
    "            separator = '&' if '?' in download_url else '?'\n",
    "            download_url = f\"{download_url}{separator}token={self.api_key}\"\n",
    "        \n",
    "        # Get filename\n",
    "        if custom_name:\n",
    "            filename = custom_name\n",
    "        else:\n",
    "            filename = self.get_filename(model_info)\n",
    "        \n",
    "        print(f\"ðŸ’¾ Downloading to: {destination}\")\n",
    "        print(f\"ðŸ“„ Filename: {filename}\")\n",
    "        \n",
    "        try:\n",
    "            filepath = self.download_file(download_url, destination, filename)\n",
    "            print(f\"\\nâœ… Successfully downloaded: {filepath}\")\n",
    "            \n",
    "            # Save model info\n",
    "            if model_info:\n",
    "                info_file = filepath + '.json'\n",
    "                with open(info_file, 'w') as f:\n",
    "                    json.dump(model_info, f, indent=2)\n",
    "                print(f\"ðŸ“‹ Model info saved to: {info_file}\")\n",
    "            \n",
    "            return filepath\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ Download failed: {e}\")\n",
    "            return None\n",
    "\n",
    "# Initialize downloader\n",
    "downloader = CivitaiDownloader(COMFYUI_BASE_PATH, CIVITAI_API_KEY)\n",
    "print(\"âœ… Downloader initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Models\n",
    "\n",
    "### Method 1: Download by URL\n",
    "Simply paste the Civitai model URL to download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Download a model by URL\n",
    "# Replace with your desired model URL\n",
    "model_url = \"https://civitai.com/models/4384/dreamshaper\"\n",
    "\n",
    "# Optional: Specify model type (checkpoint, lora, vae, etc.)\n",
    "# If not specified, it will be auto-detected\n",
    "model_type = None  # or \"checkpoint\", \"lora\", \"vae\", etc.\n",
    "\n",
    "# Download the model\n",
    "result = downloader.download_model(model_url, model_type=model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Batch Download\n",
    "Download multiple models at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models to download\n",
    "models_to_download = [\n",
    "    {\n",
    "        \"url\": \"https://civitai.com/models/4384/dreamshaper\",\n",
    "        \"type\": \"checkpoint\"  # optional\n",
    "    },\n",
    "    {\n",
    "        \"url\": \"https://civitai.com/models/7808/easynegative\",\n",
    "        \"type\": \"embedding\"\n",
    "    },\n",
    "    # Add more models here\n",
    "]\n",
    "\n",
    "# Download all models\n",
    "results = []\n",
    "for model in models_to_download:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    result = downloader.download_model(\n",
    "        model['url'], \n",
    "        model_type=model.get('type')\n",
    "    )\n",
    "    results.append(result)\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\nðŸ“Š Download Summary:\")\n",
    "success_count = sum(1 for r in results if r is not None)\n",
    "print(f\"âœ… Successful: {success_count}/{len(results)}\")\n",
    "print(f\"âŒ Failed: {len(results) - success_count}/{len(results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: Download by Model/Version ID\n",
    "If you know the specific model or version ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download by version ID (more specific)\n",
    "version_id = \"128713\"  # Example version ID\n",
    "download_url = f\"https://civitai.com/api/download/models/{version_id}\"\n",
    "\n",
    "result = downloader.download_model(download_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_downloaded_models():\n",
    "    \"\"\"List all downloaded models in ComfyUI folders\"\"\"\n",
    "    print(\"ðŸ“¦ Downloaded Models:\\n\")\n",
    "    \n",
    "    for model_type, folder in MODEL_FOLDERS.items():\n",
    "        path = os.path.join(COMFYUI_BASE_PATH, folder)\n",
    "        if os.path.exists(path):\n",
    "            files = [f for f in os.listdir(path) \n",
    "                    if f.endswith(('.safetensors', '.ckpt', '.pt', '.pth', '.bin'))]\n",
    "            \n",
    "            if files:\n",
    "                print(f\"ðŸ“ {model_type.upper()} ({len(files)} models):\")\n",
    "                for file in sorted(files)[:5]:  # Show first 5\n",
    "                    size = os.path.getsize(os.path.join(path, file)) / (1024**3)  # GB\n",
    "                    print(f\"   â€¢ {file} ({size:.2f} GB)\")\n",
    "                if len(files) > 5:\n",
    "                    print(f\"   ... and {len(files) - 5} more\")\n",
    "                print()\n",
    "\n",
    "# List current models\n",
    "list_downloaded_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_duplicate_models():\n",
    "    \"\"\"Remove duplicate model files (keeps the largest file)\"\"\"\n",
    "    print(\"ðŸ§¹ Checking for duplicate models...\\n\")\n",
    "    \n",
    "    for model_type, folder in MODEL_FOLDERS.items():\n",
    "        path = os.path.join(COMFYUI_BASE_PATH, folder)\n",
    "        if not os.path.exists(path):\n",
    "            continue\n",
    "        \n",
    "        # Group files by base name\n",
    "        file_groups = {}\n",
    "        for file in os.listdir(path):\n",
    "            if file.endswith(('.safetensors', '.ckpt', '.pt', '.pth')):\n",
    "                base_name = re.sub(r'[_-]v\\d+.*', '', file.rsplit('.', 1)[0])\n",
    "                if base_name not in file_groups:\n",
    "                    file_groups[base_name] = []\n",
    "                file_groups[base_name].append(file)\n",
    "        \n",
    "        # Check for duplicates\n",
    "        for base_name, files in file_groups.items():\n",
    "            if len(files) > 1:\n",
    "                print(f\"ðŸ“ Found duplicates for {base_name}:\")\n",
    "                \n",
    "                # Sort by file size (keep largest)\n",
    "                files_with_size = []\n",
    "                for file in files:\n",
    "                    filepath = os.path.join(path, file)\n",
    "                    size = os.path.getsize(filepath)\n",
    "                    files_with_size.append((file, size, filepath))\n",
    "                \n",
    "                files_with_size.sort(key=lambda x: x[1], reverse=True)\n",
    "                \n",
    "                print(f\"   âœ… Keeping: {files_with_size[0][0]} ({files_with_size[0][1]/(1024**3):.2f} GB)\")\n",
    "                for file, size, filepath in files_with_size[1:]:\n",
    "                    print(f\"   âŒ Would remove: {file} ({size/(1024**3):.2f} GB)\")\n",
    "                    # Uncomment to actually delete:\n",
    "                    # os.remove(filepath)\n",
    "                print()\n",
    "\n",
    "# Check for duplicates (dry run - doesn't delete)\n",
    "clean_duplicate_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disk_usage():\n",
    "    \"\"\"Check disk usage of model folders\"\"\"\n",
    "    print(\"ðŸ’¾ Disk Usage Report:\\n\")\n",
    "    \n",
    "    total_size = 0\n",
    "    folder_sizes = {}\n",
    "    \n",
    "    for model_type, folder in MODEL_FOLDERS.items():\n",
    "        path = os.path.join(COMFYUI_BASE_PATH, folder)\n",
    "        if os.path.exists(path):\n",
    "            size = 0\n",
    "            for dirpath, dirnames, filenames in os.walk(path):\n",
    "                for filename in filenames:\n",
    "                    filepath = os.path.join(dirpath, filename)\n",
    "                    if os.path.exists(filepath):\n",
    "                        size += os.path.getsize(filepath)\n",
    "            \n",
    "            folder_sizes[model_type] = size\n",
    "            total_size += size\n",
    "    \n",
    "    # Sort by size\n",
    "    sorted_folders = sorted(folder_sizes.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for model_type, size in sorted_folders:\n",
    "        size_gb = size / (1024**3)\n",
    "        if size_gb > 0.01:  # Only show if > 10MB\n",
    "            bar_length = int(size_gb / max(folder_sizes.values()) * (1024**3) * 40)\n",
    "            bar = 'â–ˆ' * bar_length\n",
    "            print(f\"{model_type:12} {bar} {size_gb:.2f} GB\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Total: {total_size/(1024**3):.2f} GB\")\n",
    "\n",
    "# Check disk usage\n",
    "get_disk_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Download Templates\n",
    "\n",
    "Common models you might want to download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Popular SD 1.5 checkpoints\n",
    "sd15_models = [\n",
    "    \"https://civitai.com/models/4384/dreamshaper\",  # DreamShaper\n",
    "    \"https://civitai.com/models/6424/chilloutmix\",  # ChilloutMix\n",
    "    \"https://civitai.com/models/43331/majicmix-realistic\",  # MajicMix\n",
    "]\n",
    "\n",
    "# Popular SDXL checkpoints\n",
    "sdxl_models = [\n",
    "    \"https://civitai.com/models/101055/sd-xl\",  # SDXL Base\n",
    "    \"https://civitai.com/models/112902/dreamshaper-xl\",  # DreamShaper XL\n",
    "    \"https://civitai.com/models/133005/juggernaut-xl\",  # Juggernaut XL\n",
    "]\n",
    "\n",
    "# Essential embeddings\n",
    "embeddings = [\n",
    "    \"https://civitai.com/models/7808/easynegative\",  # EasyNegative\n",
    "    \"https://civitai.com/models/16993/badhandsv4-animeillustdiffusion\",  # BadHands\n",
    "]\n",
    "\n",
    "# Choose which set to download\n",
    "# models_to_download = sd15_models  # Uncomment to download SD 1.5 models\n",
    "# models_to_download = sdxl_models  # Uncomment to download SDXL models\n",
    "# models_to_download = embeddings  # Uncomment to download embeddings\n",
    "\n",
    "print(\"Ready to download. Uncomment the model set you want to download.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}